{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "104fb02b",
   "metadata": {},
   "source": [
    "# Introducción\n",
    "\n",
    "En este proyecto, se aborda el problema de la evaluación de similitud semántica entre pares de oraciones. Este es un desafío fundamental en el procesamiento del lenguaje natural (NLP), con aplicaciones en tareas como recuperación de información, detección de plagio, sistemas de recomendación y más.\n",
    "\n",
    "Este trabajo forma parte de la materia **Deep Learning para NLP**, donde se exploran técnicas avanzadas para resolver problemas complejos en el ámbito del lenguaje natural.\n",
    "\n",
    "Para resolver este problema, se implementan y comparan tres enfoques basados en modelos de lenguaje preentrenados (BERT y variantes optimizadas para similitud semántica). Los modelos utilizados son:\n",
    "\n",
    "1. **BERT + Regresión**: Un modelo basado en BERT con una capa de regresión para predecir la similitud.\n",
    "2. **Siamese BERT**: Un modelo siamés que compara las representaciones de dos oraciones.\n",
    "3. **Cross-Attention Model**: Un modelo que utiliza atención cruzada para capturar interacciones entre las oraciones.\n",
    "\n",
    "El objetivo es entrenar y evaluar estos modelos en el conjunto de datos STS Benchmark, normalizando las etiquetas a un rango de 0 a 1. Finalmente, se validan los modelos con ejemplos de prueba para analizar su desempeño en diferentes niveles de similitud semántica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3239213f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import psutil\n",
    "import os\n",
    "import pandas as pd\n",
    "from datasets import load_dataset, Dataset\n",
    "from transformers import AutoTokenizer, AutoModel, DataCollatorWithPadding, get_scheduler\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import Dataset as TorchDataset, DataLoader\n",
    "from torch.nn import Module\n",
    "from scipy.stats import pearsonr\n",
    "from sentence_transformers import SentenceTransformer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1de3660",
   "metadata": {},
   "source": [
    "Configuracion para la Reproducibilidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c5c1b46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed para asegurar reproducibilidad sin importar el dispositivo en el que se ejecute\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea29eb8",
   "metadata": {},
   "source": [
    "Configurando el Dispositivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "cde0814c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Configurar dispositivo\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6769eb75",
   "metadata": {},
   "source": [
    "### Carga y Preprocesamiento del Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "098c8e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar dataset (STS-B o personalizado)\n",
    "def load_custom_dataset(csv_path=None):\n",
    "    if csv_path:\n",
    "        # Cargar dataset personalizado desde CSV\n",
    "        df = pd.read_csv(csv_path)\n",
    "        assert all(col in df.columns for col in ['sentence1', 'sentence2', 'score']), \"CSV debe tener columnas: sentence1, sentence2, score\"\n",
    "        dataset = Dataset.from_pandas(df)\n",
    "    else:\n",
    "        # Usar dataset de ejemplo (tecnología) si no se proporciona CSV\n",
    "        data = {\n",
    "            'sentence1': [\n",
    "                \"The new smartphone has a 120Hz display.\",\n",
    "                \"AI algorithms improve processing speed.\",\n",
    "                \"The laptop features a high-capacity SSD.\",\n",
    "                \"Cloud computing enhances scalability.\",\n",
    "                \"Quantum computers solve complex problems.\"\n",
    "            ],\n",
    "            'sentence2': [\n",
    "                \"This phone offers a smooth 120Hz screen.\",\n",
    "                \"Machine learning boosts performance.\",\n",
    "                \"The notebook includes a fast SSD drive.\",\n",
    "                \"Cloud services improve flexibility.\",\n",
    "                \"Traditional computers handle simple tasks.\"\n",
    "            ],\n",
    "            'score': [4.8, 4.5, 4.7, 4.6, 2.0]\n",
    "        }\n",
    "        dataset = Dataset.from_dict(data)\n",
    "    # Normalizar puntuaciones a [0, 1]\n",
    "    def normalize_labels(examples):\n",
    "        examples[\"score\"] = [s / 5.0 for s in examples[\"score\"]]\n",
    "        return examples\n",
    "    dataset = dataset.map(normalize_labels, batched=True)\n",
    "    return dataset\n",
    "\n",
    "# Cargar dataset (cambiar csv_path a tu archivo CSV si tienes uno)\n",
    "csv_path = None  # Ejemplo: \"path/to/your/dataset.csv\"\n",
    "dataset = load_dataset(\"mteb/stsbenchmark-sts\") if csv_path is None else load_custom_dataset(csv_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af90c05",
   "metadata": {},
   "source": [
    "Tokenizacion del Texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5e3d9915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b56d00fdab84807907efbab4de75b52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5749 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88a107618b44430dbc2a3e3e09bfd866",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a7b11afda37447185fe18da8cb351a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1379 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Creamos un tokenizador para convertir las frases en IDs de tokens que el modelo pueda procesar. Usare BERT o un modelo optimizado para similitud semántica\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/paraphrase-MiniLM-L6-v2\")\n",
    "\n",
    "#Definiendo la funcion de tokenizacion\n",
    "def tokenize_function(examples):\n",
    "    #Tokenizando sentence1 y sentence2 por separado\n",
    "    #Esto es necesario porque el modelo espera que las entradas sean pares de oraciones\n",
    "    #y no una sola oración.\n",
    "    encodings1 = tokenizer(\n",
    "        examples['sentence1'],\n",
    "        padding =False,\n",
    "        truncation=True,\n",
    "        max_length=128,\n",
    "        return_tensors=None # Lo dejo como lista para el dataset\n",
    "    )\n",
    "    encodings2 = tokenizer(\n",
    "        examples['sentence2'],\n",
    "        padding=False,\n",
    "        truncation=True,\n",
    "        max_length=128,\n",
    "        return_tensors=None # Lo dejo como lista para el dataset\n",
    "    )\n",
    "    return{\n",
    "        'input_ids1': encodings1['input_ids'],\n",
    "        'attention_mask1': encodings1['attention_mask'],\n",
    "        'input_ids2': encodings2['input_ids'],\n",
    "        'attention_mask2': encodings2['attention_mask'],\n",
    "        'score': examples['score'] # Mantengo la etiqueta original\n",
    "    }\n",
    "    \n",
    "#Tokenizando el dataset\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49367791",
   "metadata": {},
   "source": [
    "Probando 123..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "343660e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longitud máxima input_ids1: 70\n",
      "Longitud máxima input_ids2: 63\n"
     ]
    }
   ],
   "source": [
    "# Verificar longitudes máximas\n",
    "max_len1 = max(len(x) for x in tokenized_datasets['train']['input_ids1'])\n",
    "max_len2 = max(len(x) for x in tokenized_datasets['train']['input_ids2'])\n",
    "print(f\"Longitud máxima input_ids1: {max_len1}\")\n",
    "print(f\"Longitud máxima input_ids2: {max_len2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f844df6c",
   "metadata": {},
   "source": [
    "Creando el Dataset para Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1b3a88df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creo una clase para formatear los datos de entrada correctamente para PyTorch\n",
    "class STSDataset(TorchDataset):\n",
    "    def __init__(self, data):\n",
    "        self.input_ids1 = data[\"input_ids1\"]\n",
    "        self.attention_mask1 = data[\"attention_mask1\"]\n",
    "        self.input_ids2 = data[\"input_ids2\"]\n",
    "        self.attention_mask2 = data[\"attention_mask2\"]\n",
    "        self.scores = data[\"score\"]\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids1)\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids1': self.input_ids1[idx],\n",
    "            'attention_mask1': self.attention_mask1[idx],\n",
    "            'input_ids2': self.input_ids2[idx],\n",
    "            'attention_mask2': self.attention_mask2[idx],\n",
    "            'labels': self.scores[idx]\n",
    "        }\n",
    "\n",
    "# Dividir dataset\n",
    "if 'train' in tokenized_datasets:\n",
    "    train_dataset = STSDataset(tokenized_datasets[\"train\"])\n",
    "    val_dataset = STSDataset(tokenized_datasets[\"validation\"])\n",
    "    test_dataset = STSDataset(tokenized_datasets[\"test\"])\n",
    "else:\n",
    "    # Si es un dataset personalizado, dividir manualmente\n",
    "    dataset = tokenized_datasets.train_test_split(test_size=0.2, seed=42)\n",
    "    train_val = dataset['train'].train_test_split(test_size=0.25, seed=42)  # 60% train, 20% val, 20% test\n",
    "    train_dataset = STSDataset(train_val['train'])\n",
    "    val_dataset = STSDataset(train_val['test'])\n",
    "    test_dataset = STSDataset(dataset['test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61942763",
   "metadata": {},
   "source": [
    "Creando un DataCollator Customizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e488f1c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids1 shape: torch.Size([8, 23])\n",
      "input_ids2 shape: torch.Size([8, 18])\n"
     ]
    }
   ],
   "source": [
    "class CustomDataCollatorWithPadding:\n",
    "    def __init__(self, tokenizer, max_length=128):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.padding_collator = DataCollatorWithPadding(tokenizer, max_length=max_length)\n",
    "    \n",
    "    def __call__(self, examples):\n",
    "        features1 = [\n",
    "            {'input_ids': ex['input_ids1'], 'attention_mask': ex['attention_mask1']}\n",
    "            for ex in examples\n",
    "        ]\n",
    "        features2 = [\n",
    "            {'input_ids': ex['input_ids2'], 'attention_mask': ex['attention_mask2']}\n",
    "            for ex in examples\n",
    "        ]\n",
    "        labels = [ex['labels'] for ex in examples]\n",
    "        batch1 = self.padding_collator(features1)\n",
    "        batch2 = self.padding_collator(features2)\n",
    "        batch = {\n",
    "            'input_ids1': batch1['input_ids'],\n",
    "            'attention_mask1': batch1['attention_mask'],\n",
    "            'input_ids2': batch2['input_ids'],\n",
    "            'attention_mask2': batch2['attention_mask'],\n",
    "            'labels': torch.tensor(labels, dtype=torch.float32)\n",
    "        }\n",
    "        return batch\n",
    "\n",
    "data_collator = CustomDataCollatorWithPadding(tokenizer, max_length=128)\n",
    "\n",
    "\n",
    "# Creando los DataLoaders\n",
    "batch_size = 8\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=data_collator)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=data_collator)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=data_collator)\n",
    "\n",
    "# Para verificar formas del batch\n",
    "for batch in train_loader:\n",
    "    print(f\"input_ids1 shape: {batch['input_ids1'].shape}\")\n",
    "    print(f\"input_ids2 shape: {batch['input_ids2'].shape}\")\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6f9d89",
   "metadata": {},
   "source": [
    "### Definiendo los Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4d1d49",
   "metadata": {},
   "source": [
    "Modelo 1 : Siamese BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "48b902a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definiendo el primer modelo a utilizar, en este caso estaremos utilizando el modelo de \n",
    "# Sentence Transformers \"all-MiniLM-L6-v2\".\n",
    "# Este modelo es un modelo de transformador optimizado para tareas de similitud semántica.\n",
    "# Se congela un número configurable de capas iniciales del modelo BERT para reducir el costo computacional.\n",
    "# La salida de las dos oraciones se concatena y pasa por una red neuronal para predecir la similitud.\n",
    "class SentenceSimilarityModelOne(Module):\n",
    "    def __init__(self, model_name=\"sentence-transformers/all-MiniLM-L6-v2\", freeze_layers=2):\n",
    "        super().__init__()\n",
    "        self.bert = AutoModel.from_pretrained(model_name)\n",
    "        for i, param in enumerate(self.bert.encoder.layer):\n",
    "            if i < (len(self.bert.encoder.layer) - freeze_layers):\n",
    "                for p in param.parameters():\n",
    "                    p.requires_grad = False\n",
    "        self.regressor = torch.nn.Sequential(\n",
    "            torch.nn.Linear(384 * 2, 256),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(256, 1),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, input_ids1, attention_mask1, input_ids2, attention_mask2):\n",
    "        output1 = self.bert(input_ids1, attention_mask=attention_mask1).last_hidden_state[:, 0, :]\n",
    "        output2 = self.bert(input_ids2, attention_mask=attention_mask2).last_hidden_state[:, 0, :]\n",
    "        combined = torch.cat([output1, output2], dim=1)\n",
    "        return self.regressor(combined).squeeze()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a63236",
   "metadata": {},
   "source": [
    "Modelo 2: Siamese BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5842d265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definiendo el segundo modelo a utilizar, este modelo es una variante de BERT conocida como Siamese BERT.\n",
    "# Siamese BERT utiliza dos instancias del modelo BERT para procesar dos oraciones de forma independiente.\n",
    "# Luego, combina las representaciones de las oraciones utilizando operaciones como la diferencia absoluta y el producto elemento a elemento.\n",
    "# Finalmente, una red neuronal realiza la regresión para predecir la similitud semántica entre las oraciones.\n",
    "class SiameseBERT(Module):\n",
    "    def __init__(self, model_name=\"sentence-transformers/all-MiniLM-L6-v2\", freeze_layers=0):\n",
    "        super().__init__()\n",
    "        self.bert = AutoModel.from_pretrained(model_name)\n",
    "        # Congelar capas según parámetro freeze_layers\n",
    "        for i, param in enumerate(self.bert.encoder.layer):\n",
    "            if i < (len(self.bert.encoder.layer) - freeze_layers):\n",
    "                for p in param.parameters():\n",
    "                    p.requires_grad = False\n",
    "        self.regressor = torch.nn.Sequential(\n",
    "            torch.nn.Linear(384 * 3, 256),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(256, 1)\n",
    "        )\n",
    "    def forward(self, input_ids1, attention_mask1, input_ids2, attention_mask2):\n",
    "        output1 = self.bert(input_ids1, attention_mask=attention_mask1).last_hidden_state[:, 0, :]\n",
    "        output2 = self.bert(input_ids2, attention_mask=attention_mask2).last_hidden_state[:, 0, :]\n",
    "        diff = torch.abs(output1 - output2)\n",
    "        mult = output1 * output2\n",
    "        combined = torch.cat([diff, mult, output1], dim=1)\n",
    "        return self.regressor(combined).squeeze()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2949525",
   "metadata": {},
   "source": [
    "Modelo 3: Cross-Attention Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9254d5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definiendo el tercer modelo a utilizar, este modelo utiliza atención cruzada para capturar interacciones entre las representaciones de dos oraciones.\n",
    "# Se basa en un modelo de transformador preentrenado (paraphrase-MiniLM-L6-v2) y aplica atención cruzada para combinar las representaciones de las oraciones.\n",
    "# Finalmente, utiliza una red neuronal para predecir la similitud semántica entre las oraciones.\n",
    "class CrossAttentionModel(Module):\n",
    "    def __init__(self, model_name=\"sentence-transformers/all-MiniLM-L6-v2\", freeze_layers=2):\n",
    "        super().__init__()\n",
    "        self.bert = AutoModel.from_pretrained(model_name)\n",
    "        for i, param in enumerate(self.bert.encoder.layer):\n",
    "            if i < (len(self.bert.encoder.layer) - freeze_layers):\n",
    "                for p in param.parameters():\n",
    "                    p.requires_grad = False\n",
    "        self.attention = torch.nn.MultiheadAttention(embed_dim=384, num_heads=8)\n",
    "        self.regressor = torch.nn.Sequential(\n",
    "            torch.nn.Linear(384 * 2, 256),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(256, 1),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, input_ids1, attention_mask1, input_ids2, attention_mask2):\n",
    "        output1 = self.bert(input_ids1, attention_mask=attention_mask1).last_hidden_state\n",
    "        output2 = self.bert(input_ids2, attention_mask=attention_mask2).last_hidden_state\n",
    "        mask1 = attention_mask1.unsqueeze(-1).expand_as(output1)\n",
    "        mask2 = attention_mask2.unsqueeze(-1).expand_as(output2)\n",
    "        output1 = (output1 * mask1).sum(dim=1) / mask1.sum(dim=1)\n",
    "        output2 = (output2 * mask2).sum(dim=1) / mask2.sum(dim=1)\n",
    "        output1 = output1.unsqueeze(0)\n",
    "        output2 = output2.unsqueeze(0)\n",
    "        attn_output, _ = self.attention(output1, output2, output2)\n",
    "        attn_output = attn_output.squeeze(0)\n",
    "        combined = torch.cat([output1.squeeze(0), attn_output], dim=1)\n",
    "        return self.regressor(combined).squeeze()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18a502b",
   "metadata": {},
   "source": [
    "### Configuracion del Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "dde5623f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Inicializando los modelos\n",
    "model1 = SentenceSimilarityModelOne().to(device)\n",
    "model2 = SiameseBERT().to(device)\n",
    "model3 = CrossAttentionModel().to(device)\n",
    "\n",
    "# Definiendo la  función de pérdida de correlación\n",
    "def pearson_correlation_loss(outputs, targets):\n",
    "    outputs = outputs - torch.mean(outputs)\n",
    "    targets = targets - torch.mean(targets)\n",
    "    norm_outputs = torch.sqrt(torch.sum(outputs ** 2))\n",
    "    norm_targets = torch.sqrt(torch.sum(targets ** 2))\n",
    "    correlation = torch.sum(outputs * targets) / (norm_outputs * norm_targets)\n",
    "    return 1 - correlation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e249a3e7",
   "metadata": {},
   "source": [
    "Validando el Fine - Tuning de los Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6e682144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BERT + Regresión:\n",
      "Total Parámetros: 22,910,337, Entrenables: 15,812,481\n",
      "\n",
      "Siamese BERT:\n",
      "Total Parámetros: 23,008,641, Entrenables: 12,361,857\n",
      "\n",
      "Cross-Attention:\n",
      "Total Parámetros: 23,501,697, Entrenables: 16,403,841\n"
     ]
    }
   ],
   "source": [
    "def print_trainable_params(model):\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"Total Parámetros: {total_params:,}, Entrenables: {trainable_params:,}\")\n",
    "\n",
    "print(\"\\nBERT + Regresión:\")\n",
    "print_trainable_params(model1)\n",
    "\n",
    "print(\"\\nSiamese BERT:\")\n",
    "print_trainable_params(model2)\n",
    "\n",
    "print(\"\\nCross-Attention:\")\n",
    "print_trainable_params(model3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d8a2a8",
   "metadata": {},
   "source": [
    "Monitoreo de los recursos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa98676",
   "metadata": {},
   "source": [
    "### Evaluación del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5e85a2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función de evaluación\n",
    "def evaluate_model(model, val_loader, model_type=\"bert\"):\n",
    "    model.eval()\n",
    "    preds, labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            inputs1 = batch[\"input_ids1\"].to(device)\n",
    "            mask1 = batch[\"attention_mask1\"].to(device)\n",
    "            inputs2 = batch[\"input_ids2\"].to(device)\n",
    "            mask2 = batch[\"attention_mask2\"].to(device)\n",
    "            lbls = batch[\"labels\"].to(device)\n",
    "            outputs = model(inputs1, mask1, inputs2, mask2)\n",
    "            preds.extend(outputs.cpu().numpy())\n",
    "            labels.extend(lbls.cpu().numpy())\n",
    "    correlation, _ = pearsonr(preds, labels)\n",
    "    return correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2c95563b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def weighted_mse_loss(output, target):\n",
    "#     weights = torch.where(target < 1,2.0,1.0) # para similitudes muy bajas, se penaliza más\n",
    "#     return torch.mean(weights * (output - target) ** 2)\n",
    "\n",
    "# Función para entrenar modelo con diferentes configuraciones\n",
    "def train_model(model, train_loader, val_loader, model_type=\"bert\", epochs=3, lr=3e-5, output_dir=\"./checkpoints\"):\n",
    "    model.train()\n",
    "    optimizer = AdamW(model.parameters(), lr=lr)\n",
    "    scheduler = get_scheduler(\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=len(train_loader) * epochs)\n",
    "    history = []\n",
    "    best_pearson = -float(\"inf\")\n",
    "    best_model_path = os.path.join(output_dir, f\"best_model_{model_type}.pt\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            inputs1 = batch[\"input_ids1\"].to(device)\n",
    "            mask1 = batch[\"attention_mask1\"].to(device)\n",
    "            inputs2 = batch[\"input_ids2\"].to(device)\n",
    "            mask2 = batch[\"attention_mask2\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "            outputs = model(inputs1, mask1, inputs2, mask2)\n",
    "            if model_type == \"siamese\":\n",
    "                loss = pearson_correlation_loss(outputs, labels)\n",
    "            else:\n",
    "                loss = torch.nn.MSELoss()(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            total_loss += loss.item()\n",
    "            torch.cuda.empty_cache()\n",
    "        avg_train_loss = total_loss / len(train_loader)\n",
    "        pearson_corr = evaluate_model(model, val_loader, model_type)\n",
    "        history.append((avg_train_loss, pearson_corr))\n",
    "        print(f\"{model_type.upper()} - Epoch {epoch+1}/{epochs} - Loss: {avg_train_loss:.4f}, Pearson: {pearson_corr:.4f}\")\n",
    "        if pearson_corr > best_pearson:\n",
    "            best_pearson = pearson_corr\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            print(f\"Mejor modelo guardado con correlación de Pearson: {best_pearson:.4f}\")\n",
    "    model.load_state_dict(torch.load(best_model_path))\n",
    "    print(f\"{model_type.upper()} - Entrenamiento finalizado. Mejor modelo cargado: {best_pearson:.4f}\")\n",
    "    return history, best_pearson\n",
    "\n",
    "def evaluate_on_test(model, test_loader, model_type=\"bert\"):\n",
    "    person_corr = evaluate_model(model, test_loader, model_type)\n",
    "    print(f\"{model_type.upper()} - Evaluación en test - Pearson Correlation: {person_corr:.4f}\")\n",
    "    return person_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b3dc49d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función de inferencia\n",
    "def infer_similarity(model, tokenizer, sentence1, sentence2):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        encoded1 = tokenizer(\n",
    "            sentence1,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=128,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(device)\n",
    "        encoded2 = tokenizer(\n",
    "            sentence2,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=128,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(device)\n",
    "        similarity = model(\n",
    "            encoded1[\"input_ids\"],\n",
    "            encoded1[\"attention_mask\"],\n",
    "            encoded2[\"input_ids\"],\n",
    "            encoded2[\"attention_mask\"]\n",
    "        )\n",
    "        # Normalizar salida a [0, 5]\n",
    "        if isinstance(model, SiameseBERT):\n",
    "            similarity = torch.tanh(similarity) * 2.5 + 2.5  # Mapear a [0, 5]\n",
    "        else:\n",
    "            similarity = similarity * 5\n",
    "    return similarity.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c3a56732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando BERT + Regresión...\n",
      "BERT - Epoch 1/3 - Loss: 5.1189, Pearson: 0.1707\n",
      "Mejor modelo guardado con correlación de Pearson: 0.1707\n",
      "BERT - Epoch 2/3 - Loss: 5.0379, Pearson: 0.1716\n",
      "Mejor modelo guardado con correlación de Pearson: 0.1716\n",
      "BERT - Epoch 3/3 - Loss: 5.0379, Pearson: 0.1718\n",
      "Mejor modelo guardado con correlación de Pearson: 0.1718\n",
      "BERT - Entrenamiento finalizado. Mejor modelo cargado: 0.1718\n",
      "Correlación de Pearson en validación para BERT + Regresión: 0.1718\n",
      "\n",
      "Entrenando Siamese BERT...\n",
      "SIAMESE - Epoch 1/3 - Loss: 0.3508, Pearson: 0.8182\n",
      "Mejor modelo guardado con correlación de Pearson: 0.8182\n",
      "SIAMESE - Epoch 2/3 - Loss: 0.2729, Pearson: 0.8240\n",
      "Mejor modelo guardado con correlación de Pearson: 0.8240\n",
      "SIAMESE - Epoch 3/3 - Loss: 0.2439, Pearson: 0.8251\n",
      "Mejor modelo guardado con correlación de Pearson: 0.8251\n",
      "SIAMESE - Entrenamiento finalizado. Mejor modelo cargado: 0.8251\n",
      "Correlación de Pearson en validación para Siamese BERT: 0.8251\n",
      "\n",
      "Entrenando Cross-Attention...\n",
      "CROSS - Epoch 1/3 - Loss: 5.1273, Pearson: 0.0637\n",
      "Mejor modelo guardado con correlación de Pearson: 0.0637\n",
      "CROSS - Epoch 2/3 - Loss: 5.0380, Pearson: 0.0533\n",
      "CROSS - Epoch 3/3 - Loss: 5.0370, Pearson: 0.0507\n",
      "CROSS - Entrenamiento finalizado. Mejor modelo cargado: 0.0637\n",
      "Correlación de Pearson en validación para Cross-Attention: 0.0637\n"
     ]
    }
   ],
   "source": [
    "# Entrenar y evaluar modelos\n",
    "models = {\n",
    "    \"BERT + Regresión\": (model1, \"bert\"),\n",
    "    \"Siamese BERT\": (model2, \"siamese\"),\n",
    "    \"Cross-Attention\": (model3, \"cross\")\n",
    "}\n",
    "test_results = {}\n",
    "for model_name, (model, model_type) in models.items():\n",
    "    print(f\"\\nEntrenando {model_name}...\")\n",
    "    history, best_pearson = train_model(model, train_loader, val_loader, model_type=model_type)\n",
    "    test_results[model_name] = best_pearson\n",
    "    print(f\"Correlación de Pearson en validación para {model_name}: {best_pearson:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "28d58429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluando BERT + Regresión en ejemplos de prueba:\n",
      "Ejemplo 1: I love eating apples | The capital of France is Paris → Score: 5.00 --> 5\n",
      "Ejemplo 2: I have a black cat | My pet is a dog → Score: 5.00 --> 5\n",
      "Ejemplo 3: He plays soccer on weekends | She enjoys playing tennis on Sundays → Score: 5.00 --> 5\n",
      "Ejemplo 4: The sun is shining in the sky | It is a bright and sunny day → Score: 5.00 --> 5\n",
      "Ejemplo 5: The smartphone has a large screen | This phone features a big display → Score: 5.00 --> 5\n",
      "Ejemplo 6: The dog is barking loudly | The dog is barking loudly → Score: 5.00 --> 5\n",
      "\n",
      "Evaluando Siamese BERT en ejemplos de prueba:\n",
      "Ejemplo 1: I love eating apples | The capital of France is Paris → Score: 0.83 --> 1\n",
      "Ejemplo 2: I have a black cat | My pet is a dog → Score: 1.43 --> 1\n",
      "Ejemplo 3: He plays soccer on weekends | She enjoys playing tennis on Sundays → Score: 1.37 --> 1\n",
      "Ejemplo 4: The sun is shining in the sky | It is a bright and sunny day → Score: 2.00 --> 2\n",
      "Ejemplo 5: The smartphone has a large screen | This phone features a big display → Score: 2.08 --> 2\n",
      "Ejemplo 6: The dog is barking loudly | The dog is barking loudly → Score: 2.74 --> 3\n",
      "\n",
      "Evaluando Cross-Attention en ejemplos de prueba:\n",
      "Ejemplo 1: I love eating apples | The capital of France is Paris → Score: 5.00 --> 5\n",
      "Ejemplo 2: I have a black cat | My pet is a dog → Score: 5.00 --> 5\n",
      "Ejemplo 3: He plays soccer on weekends | She enjoys playing tennis on Sundays → Score: 5.00 --> 5\n",
      "Ejemplo 4: The sun is shining in the sky | It is a bright and sunny day → Score: 5.00 --> 5\n",
      "Ejemplo 5: The smartphone has a large screen | This phone features a big display → Score: 5.00 --> 5\n",
      "Ejemplo 6: The dog is barking loudly | The dog is barking loudly → Score: 5.00 --> 5\n",
      "\n",
      "Evaluando modelo preentrenado en ejemplos de prueba:\n",
      "Ejemplo 1: I love eating apples | The capital of France is Paris → Score: -0.43 --> 0\n",
      "Ejemplo 2: I have a black cat | My pet is a dog → Score: 1.79 --> 2\n",
      "Ejemplo 3: He plays soccer on weekends | She enjoys playing tennis on Sundays → Score: 2.09 --> 2\n",
      "Ejemplo 4: The sun is shining in the sky | It is a bright and sunny day → Score: 3.28 --> 3\n",
      "Ejemplo 5: The smartphone has a large screen | This phone features a big display → Score: 4.28 --> 4\n",
      "Ejemplo 6: The dog is barking loudly | The dog is barking loudly → Score: 5.00 --> 5\n"
     ]
    }
   ],
   "source": [
    "# Evaluar en ejemplos de prueba\n",
    "test_sentences = [\n",
    "    (\"I love eating apples\", \"The capital of France is Paris\"),\n",
    "    (\"I have a black cat\", \"My pet is a dog\"),\n",
    "    (\"He plays soccer on weekends\", \"She enjoys playing tennis on Sundays\"),\n",
    "    (\"The sun is shining in the sky\", \"It is a bright and sunny day\"),\n",
    "    (\"The smartphone has a large screen\", \"This phone features a big display\"),\n",
    "    (\"The dog is barking loudly\", \"The dog is barking loudly\")\n",
    "]\n",
    "for model_name, (model, model_type) in models.items():\n",
    "    print(f\"\\nEvaluando {model_name} en ejemplos de prueba:\")\n",
    "    for i, (s1, s2) in enumerate(test_sentences):\n",
    "        score = infer_similarity(model, tokenizer, s1, s2)\n",
    "        print(f\"Ejemplo {i+1}: {s1} | {s2} → Score: {score:.2f} --> {round(score)}\")\n",
    "\n",
    "\n",
    "\n",
    "# Comparar con modelo preentrenado\n",
    "pretrained_model = SentenceTransformer(\"paraphrase-MiniLM-L6-v2\")\n",
    "print(\"\\nEvaluando modelo preentrenado en ejemplos de prueba:\")\n",
    "for i, (s1, s2) in enumerate(test_sentences):\n",
    "    embeddings1 = pretrained_model.encode(s1)\n",
    "    embeddings2 = pretrained_model.encode(s2)\n",
    "    similarity = np.dot(embeddings1, embeddings2) / (np.linalg.norm(embeddings1) * np.linalg.norm(embeddings2))\n",
    "    score = similarity * 5\n",
    "    print(f\"Ejemplo {i+1}: {s1} | {s2} → Score: {score:.2f} --> {round(score)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8d0be4ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando BERT + Regresión en el conjunto de test...\n",
      "BERT - Evaluación en test - Pearson Correlation: 0.0060\n",
      "Correlación de Pearson en test para BERT + Regresión: 0.0060\n",
      "\n",
      "Entrenando Siamese BERT en el conjunto de test...\n",
      "SIAMESE - Evaluación en test - Pearson Correlation: 0.7832\n",
      "Correlación de Pearson en test para Siamese BERT: 0.7832\n",
      "\n",
      "Entrenando Cross-Attention en el conjunto de test...\n",
      "CROSS - Evaluación en test - Pearson Correlation: -0.0035\n",
      "Correlación de Pearson en test para Cross-Attention: -0.0035\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for model_name, (model, model_type) in models.items():\n",
    "    print(f\"\\nEntrenando {model_name} en el conjunto de test...\")\n",
    "    test_pearson = evaluate_on_test(model, test_loader, model_type)\n",
    "    test_results[model_name] = test_pearson\n",
    "    print(f\"Correlación de Pearson en test para {model_name}: {test_pearson:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
