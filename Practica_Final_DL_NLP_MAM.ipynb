{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3239213f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import evaluate\n",
    "import pandas as pd\n",
    "import textwrap\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "from datasets import load_dataset\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoTokenizer, AutoModel, get_scheduler\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1de3660",
   "metadata": {},
   "source": [
    "Configuracion para la Reproducibilidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c1b46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed para asegurar reproducibilidad sin importar el dispositivo en el que se ejecute\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6769eb75",
   "metadata": {},
   "source": [
    "### Carga y Preprocesamiento del Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098c8e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el dataset\n",
    "dataset = load_dataset(\"mteb/stsbenchmark-sts\")\n",
    "\n",
    "# Normalizar las etiquetas (de 0-5 a un rango de 0-1)\n",
    "def normalize_labels(examples):\n",
    "    examples[\"score\"] = [s / 5.0 for s in examples[\"score\"]]\n",
    "    return examples\n",
    "\n",
    "# Aplicar normalización\n",
    "dataset = dataset.map(normalize_labels, batched=True)x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af90c05",
   "metadata": {},
   "source": [
    "Tokenizacion del Texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3d9915",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos un tokenizador para convertir las frases en IDs de tokens que el modelo pueda procesar. Usare BERT o un modelo optimizado para similitud semántica\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/paraphrase-MiniLM-L6-v2\")\n",
    "\n",
    "#Definiendo la funcion de tokenizacion\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples['sentence1'],\n",
    "        examples['sentence2'],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=128\n",
    "    )\n",
    "    \n",
    "#Tokenizando el dataset\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab995de4",
   "metadata": {},
   "source": [
    "# Creando la Funcion para Fine-Tuning en los Modelos"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
